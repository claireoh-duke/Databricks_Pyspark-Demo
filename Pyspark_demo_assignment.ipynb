{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1ed6a01-9923-4d77-8c16-5d23ccfccaba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c999b001-261a-4b38-b9bf-6aff1e3f1ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0\nCluster configured successfully!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/databricks-datasets/COVID/', name='COVID/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/README.md', name='README.md', size=976, modificationTime=1596557781000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/Rdatasets/', name='Rdatasets/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/SPARK_README.md', name='SPARK_README.md', size=3359, modificationTime=1596557823000),\n",
       " FileInfo(path='dbfs:/databricks-datasets/adult/', name='adult/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/airlines/', name='airlines/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/amazon/', name='amazon/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/asa/', name='asa/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/atlas_higgs/', name='atlas_higgs/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/bikeSharing/', name='bikeSharing/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cctvVideos/', name='cctvVideos/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/credit-card-fraud/', name='credit-card-fraud/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs100/', name='cs100/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs110x/', name='cs110x/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/cs190/', name='cs190/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/data.gov/', name='data.gov/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/definitive-guide/', name='definitive-guide/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/delta-sharing/', name='delta-sharing/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flights/', name='flights/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flower_photos/', name='flower_photos/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/flowers/', name='flowers/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/genomics/', name='genomics/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/hail/', name='hail/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/identifying-campaign-effectiveness/', name='identifying-campaign-effectiveness/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/iot/', name='iot/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/iot-stream/', name='iot-stream/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/learning-spark/', name='learning-spark/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/learning-spark-v2/', name='learning-spark-v2/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/lending-club-loan-stats/', name='lending-club-loan-stats/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/med-images/', name='med-images/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/media/', name='media/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/mnist-digits/', name='mnist-digits/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/news20.binary/', name='news20.binary/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/nyctaxi/', name='nyctaxi/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/nyctaxi-with-zipcodes/', name='nyctaxi-with-zipcodes/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/online_retail/', name='online_retail/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/overlap-join/', name='overlap-join/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/power-plant/', name='power-plant/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/retail-org/', name='retail-org/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/rwe/', name='rwe/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sai-summit-2019-sf/', name='sai-summit-2019-sf/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sample_logs/', name='sample_logs/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/samples/', name='samples/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sfo_customer_survey/', name='sfo_customer_survey/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/sms_spam_collection/', name='sms_spam_collection/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/songs/', name='songs/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/structured-streaming/', name='structured-streaming/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/timeseries/', name='timeseries/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/tpch/', name='tpch/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/travel_recommendations_realtime/', name='travel_recommendations_realtime/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/warmup/', name='warmup/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/weather/', name='weather/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wiki/', name='wiki/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wikipedia-datasets/', name='wikipedia-datasets/', size=0, modificationTime=1762923943329),\n",
       " FileInfo(path='dbfs:/databricks-datasets/wine-quality/', name='wine-quality/', size=0, modificationTime=1762923943329)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Cluster configured successfully!\")\n",
    "dbutils.fs.ls(\"/databricks-datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9af1037-cbc8-4203-b12d-01c389e35455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e229ab-a6c9-4d64-84ce-cf0d9f85cd3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 1227256\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/databricks-datasets/COVID/covid-19-data/\", header=True, inferSchema=True)\n",
    "print(\"Number of Rows:\", df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6deea2a-aa73-48f0-8c4f-52afd962cce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-----+-----+------+\n|      date|     county|     state| fips|cases|deaths|\n+----------+-----------+----------+-----+-----+------+\n|2020-01-21|  Snohomish|Washington|53061|    1|     0|\n|2020-01-22|  Snohomish|Washington|53061|    1|     0|\n|2020-01-23|  Snohomish|Washington|53061|    1|     0|\n|2020-01-24|       Cook|  Illinois|17031|    1|     0|\n|2020-01-24|  Snohomish|Washington|53061|    1|     0|\n|2020-01-25|     Orange|California|06059|    1|     0|\n|2020-01-25|       Cook|  Illinois|17031|    1|     0|\n|2020-01-25|  Snohomish|Washington|53061|    1|     0|\n|2020-01-26|   Maricopa|   Arizona|04013|    1|     0|\n|2020-01-26|Los Angeles|California|06037|    1|     0|\n|2020-01-26|     Orange|California|06059|    1|     0|\n|2020-01-26|       Cook|  Illinois|17031|    1|     0|\n|2020-01-26|  Snohomish|Washington|53061|    1|     0|\n|2020-01-27|   Maricopa|   Arizona|04013|    1|     0|\n|2020-01-27|Los Angeles|California|06037|    1|     0|\n|2020-01-27|     Orange|California|06059|    1|     0|\n|2020-01-27|       Cook|  Illinois|17031|    1|     0|\n|2020-01-27|  Snohomish|Washington|53061|    1|     0|\n|2020-01-28|   Maricopa|   Arizona|04013|    1|     0|\n|2020-01-28|Los Angeles|California|06037|    1|     0|\n+----------+-----------+----------+-----+-----+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777c923b-03cf-46af-84b0-1924afd7831f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date: string (nullable = true)\n |-- county: string (nullable = true)\n |-- state: string (nullable = true)\n |-- fips: string (nullable = true)\n |-- cases: string (nullable = true)\n |-- deaths: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2800161-bfae-499e-aa61-77c1e98f36cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = (\n",
    "    df\n",
    "    .withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"cases\", F.coalesce(expr(\"try_cast(cases as int)\"), lit(0)))\n",
    "    .withColumn(\"deaths\", F.coalesce(expr(\"try_cast(deaths as int)\"), lit(0)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae321a4b-abcc-4b2d-a7f1-5aa7e26827d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date: date (nullable = true)\n |-- county: string (nullable = true)\n |-- state: string (nullable = true)\n |-- fips: string (nullable = true)\n |-- cases: integer (nullable = false)\n |-- deaths: integer (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c396fd51-9ef0-44c5-8594-7e92ea8d6296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filtered = data.filter((col(\"deaths\").isNotNull()) & (col(\"cases\").isNotNull()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e861a3e3-ee6b-4f3c-9b99-9c47b1f70fcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c5ac8cc-a57b-4bb4-8a44-4e5b49a4cd84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-1. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52affd52-e453-44cd-a030-878c0eae743a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+-----+-----+------+\n|date      |county       |state   |fips |cases|deaths|\n+----------+-------------+--------+-----+-----+------+\n|2020-03-01|New York City|New York|NULL |1    |0     |\n|2020-03-02|New York City|New York|NULL |1    |0     |\n|2020-03-03|New York City|New York|NULL |2    |0     |\n|2020-03-04|New York City|New York|NULL |2    |0     |\n|2020-03-04|Westchester  |New York|36119|9    |0     |\n|2020-03-05|Nassau       |New York|36059|1    |0     |\n|2020-03-05|New York City|New York|NULL |4    |0     |\n|2020-03-05|Westchester  |New York|36119|17   |0     |\n|2020-03-06|Nassau       |New York|36059|4    |0     |\n|2020-03-06|New York City|New York|NULL |5    |0     |\n|2020-03-06|Rockland     |New York|36087|2    |0     |\n|2020-03-06|Westchester  |New York|36119|33   |0     |\n|2020-03-07|Nassau       |New York|36059|4    |0     |\n|2020-03-07|New York City|New York|NULL |12   |0     |\n|2020-03-07|Rockland     |New York|36087|2    |0     |\n|2020-03-07|Saratoga     |New York|36091|2    |0     |\n|2020-03-07|Westchester  |New York|36119|69   |0     |\n|2020-03-08|Nassau       |New York|36059|5    |0     |\n|2020-03-08|New York City|New York|NULL |14   |0     |\n|2020-03-08|Rockland     |New York|36087|2    |0     |\n+----------+-------------+--------+-----+-----+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# 2 filter operations\n",
    "df_filtered2 = data.filter((col(\"deaths\").isNotNull()) & (col(\"state\") == \"New York\"))\n",
    "df_filtered2.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edd72a6-d7ba-4b6b-a1b4-877fb97dccea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 2-2. Join operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf87ac0-e34b-404c-a3dc-1d72cd8a45a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----+-----+------+-----------------+\n|state     |date      |county     |fips |cases|deaths|state_total_death|\n+----------+----------+-----------+-----+-----+------+-----------------+\n|Illinois  |2020-01-24|Cook       |17031|1    |0     |4352863          |\n|Illinois  |2020-01-25|Cook       |17031|1    |0     |4352863          |\n|Illinois  |2020-01-26|Cook       |17031|1    |0     |4352863          |\n|Illinois  |2020-01-27|Cook       |17031|1    |0     |4352863          |\n|California|2020-01-25|Orange     |06059|1    |0     |7480318          |\n|California|2020-01-26|Los Angeles|06037|1    |0     |7480318          |\n|California|2020-01-26|Orange     |06059|1    |0     |7480318          |\n|California|2020-01-27|Los Angeles|06037|1    |0     |7480318          |\n|California|2020-01-27|Orange     |06059|1    |0     |7480318          |\n|California|2020-01-28|Los Angeles|06037|1    |0     |7480318          |\n|California|2020-01-28|Orange     |06059|1    |0     |7480318          |\n|Arizona   |2020-01-26|Maricopa   |04013|1    |0     |2441353          |\n|Arizona   |2020-01-27|Maricopa   |04013|1    |0     |2441353          |\n|Arizona   |2020-01-28|Maricopa   |04013|1    |0     |2441353          |\n|Washington|2020-01-21|Snohomish  |53061|1    |0     |960567           |\n|Washington|2020-01-22|Snohomish  |53061|1    |0     |960567           |\n|Washington|2020-01-23|Snohomish  |53061|1    |0     |960567           |\n|Washington|2020-01-24|Snohomish  |53061|1    |0     |960567           |\n|Washington|2020-01-25|Snohomish  |53061|1    |0     |960567           |\n|Washington|2020-01-26|Snohomish  |53061|1    |0     |960567           |\n+----------+----------+-----------+-----+-----+------+-----------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df1 = df_filtered.groupBy(\"state\").agg(sum(\"deaths\").alias(\"state_total_death\"))\n",
    "df_join = df_filtered.join(df1, \"state\", \"left\")\n",
    "df_join.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b48a1b21-28e6-4c23-bc77-ab9e6a01d8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-3. Groupby aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6edc6a61-4b1e-422c-b940-0b0a2090c3ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------------+------------------+\n|               state|total_state_cases|  state_avg_deaths|state_total_deaths|\n+--------------------+-----------------+------------------+------------------+\n|                Utah|            10949| 25.95689104027765|            284202|\n|             Florida|            26230| 206.3694624475791|           5413071|\n|      North Carolina|            37909| 45.50542087630905|           1725065|\n|             Indiana|            35178| 58.11203024617659|           2044265|\n|                Ohio|            33568| 73.44268350810296|           2465324|\n|            Illinois|            38405|113.34104934253352|           4352863|\n|            Nebraska|            31790|10.655143126769424|            338727|\n|              Hawaii|             1723| 38.65351131746953|             66600|\n|             Vermont|             5773| 6.035336913216699|             34842|\n|             Montana|            18312|10.065530799475754|            184320|\n|            Oklahoma|            28800|21.308194444444446|            613676|\n|            Virginia|            50053|27.752062813417776|           1389074|\n|           Louisiana|            24968| 83.37684235821852|           2081753|\n|            Michigan|            31686|107.16786593448211|           3395721|\n|        South Dakota|            23218|11.368808682918425|            263961|\n|        North Dakota|            18953|12.134068485200233|            229977|\n|             Wyoming|             8638| 9.505325306783977|             82107|\n|              Alaska|             9398|4.1741859970206425|             39229|\n|Northern Mariana ...|              686|1.0816326530612246|               742|\n|          California|            22543|331.82442443330524|           7480318|\n+--------------------+-----------------+------------------+------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_groupby = df_filtered.groupBy(\"state\").agg(\n",
    "    count(\"*\").alias(\"total_state_cases\"),\n",
    "    avg(\"deaths\").alias(\"state_avg_deaths\"),\n",
    "    sum(\"deaths\").alias(\"state_total_deaths\")\n",
    ")\n",
    "\n",
    "df_groupby.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52552b23-76ad-4f41-b4b6-1932f59c39c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-4. Column transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e74d457c-3133-4a0c-83c0-061a4accd592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-----+-----+------+--------------+\n|      date|     county|     state| fips|cases|deaths|deaths_squared|\n+----------+-----------+----------+-----+-----+------+--------------+\n|2020-01-21|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-22|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-23|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-24|       Cook|  Illinois|17031|    1|     0|             0|\n|2020-01-24|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-25|     Orange|California|06059|    1|     0|             0|\n|2020-01-25|       Cook|  Illinois|17031|    1|     0|             0|\n|2020-01-25|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-26|   Maricopa|   Arizona|04013|    1|     0|             0|\n|2020-01-26|Los Angeles|California|06037|    1|     0|             0|\n|2020-01-26|     Orange|California|06059|    1|     0|             0|\n|2020-01-26|       Cook|  Illinois|17031|    1|     0|             0|\n|2020-01-26|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-27|   Maricopa|   Arizona|04013|    1|     0|             0|\n|2020-01-27|Los Angeles|California|06037|    1|     0|             0|\n|2020-01-27|     Orange|California|06059|    1|     0|             0|\n|2020-01-27|       Cook|  Illinois|17031|    1|     0|             0|\n|2020-01-27|  Snohomish|Washington|53061|    1|     0|             0|\n|2020-01-28|   Maricopa|   Arizona|04013|    1|     0|             0|\n|2020-01-28|Los Angeles|California|06037|    1|     0|             0|\n+----------+-----------+----------+-----+-----+------+--------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_filtered.withColumn(\"deaths_squared\", col(\"deaths\") * col(\"deaths\"))\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9aafdf-48fc-4c3a-82c1-010d931acf63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = (\n",
    "    df_raw\n",
    "    .withColumn(\"date\", F.expr(\"try_to_date(date, 'yyyy-MM-dd')\"))\n",
    "    .withColumn(\"cases\",  F.expr(\"try_cast(cases as int)\"))\n",
    "    .withColumn(\"deaths\", F.expr(\"try_cast(deaths as int)\"))\n",
    "    .filter(F.col(\"date\").isNotNull())   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "242bf632-e03a-4c32-827d-8b4606893357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS covid\")\n",
    "data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c092b7f-7b31-42be-b802-7cd39c134096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "169b907b-1f81-42a8-bd76-8078afa97dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[6] SQL Query 1: Top 10 States by Total Deaths\n+-------------+------------+\n|        state|total_deaths|\n+-------------+------------+\n|     New York|    12724140|\n|   California|     7480318|\n|        Texas|     6841454|\n|   New Jersey|     6004001|\n|      Florida|     5413071|\n|     Illinois|     4352863|\n| Pennsylvania|     4195968|\n|Massachusetts|     3717383|\n|     Michigan|     3395721|\n|      Georgia|     2835421|\n+-------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6] SQL Query 1: Top 10 States by Total Deaths\")\n",
    "query1 = \"\"\"\n",
    "    SELECT \n",
    "        state,\n",
    "        SUM(deaths) as total_deaths\n",
    "    FROM covid\n",
    "    WHERE state IS NOT NULL\n",
    "    GROUP BY state\n",
    "    ORDER BY total_deaths DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_sql1 = spark.sql(query1)\n",
    "df_sql1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea1b449-1aef-4759-b565-bf86ca9b514b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[7] SQL Query 2: Top 10 States by Total Cases\n+--------------+-----------+\n|         state|total_cases|\n+--------------+-----------+\n|    California|  505068688|\n|         Texas|  402592904|\n|       Florida|  313235465|\n|      New York|  272678258|\n|      Illinois|  195082889|\n|       Georgia|  151749782|\n|          Ohio|  134921770|\n|  Pennsylvania|  133343845|\n|    New Jersey|  128802146|\n|North Carolina|  124271360|\n+--------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[7] SQL Query 2: Top 10 States by Total Cases\")\n",
    "query2 = \"\"\"\n",
    "    SELECT \n",
    "        state,\n",
    "        SUM(cases) as total_cases\n",
    "    FROM covid\n",
    "    WHERE state IS NOT NULL\n",
    "    GROUP BY state\n",
    "    ORDER BY total_cases DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_sql2 = spark.sql(query2)\n",
    "df_sql2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f20a204b-3660-4eae-a296-1e847eefbb83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcebcff-10f3-4520-ba0c-9b4954ea0041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonProject [state#15859, date#15898, county#15858, fips#15860, cases#15900, deaths#15902, state_total_death#16812L]\n         +- PhotonShuffledHashJoin [state#15859], [state#17736], LeftOuter, BuildLeft\n            :- PhotonShuffleExchangeSource\n            :  +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#20528]\n            :     +- PhotonShuffleExchangeSink hashpartitioning(state#15859, 10)\n            :        +- PhotonProject [cast(gettimestamp(date#15857, yyyy-MM-dd, TimestampType, try_to_date, Some(Etc/UTC), true) as date) AS date#15898, county#15858, state#15859, fips#15860, coalesce(try_cast(cases#15861 as int), 0) AS cases#15900, coalesce(try_cast(deaths#15862 as int), 0) AS deaths#15902]\n            :           +- PhotonRowToColumnar\n            :              +- FileScan csv [date#15857,county#15858,state#15859,fips#15860,cases#15861,deaths#15862] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/COVID/covid-19-data], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<date:string,county:string,state:string,fips:string,cases:string,deaths:string>\n            +- PhotonGroupingAgg(keys=[state#17736], functions=[finalmerge_sum(merge sum#17743L) AS sum(deaths)#17741L])\n               +- PhotonShuffleExchangeSource\n                  +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#20539]\n                     +- PhotonShuffleExchangeSink hashpartitioning(state#17736, 10)\n                        +- PhotonGroupingAgg(keys=[state#17736], functions=[partial_sum(deaths#15902) AS sum#17743L])\n                           +- PhotonProject [state#17736, coalesce(try_cast(deaths#17739 as int), 0) AS deaths#15902]\n                              +- PhotonFilter isnotnull(state#17736)\n                                 +- PhotonRowToColumnar\n                                    +- FileScan csv [state#17736,deaths#17739] Batched: false, DataFilters: [isnotnull(state#17736)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/COVID/covid-19-data], PartitionFilters: [], PushedFilters: [IsNotNull(state)], ReadSchema: struct<state:string,deaths:string>\n\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n"
     ]
    }
   ],
   "source": [
    "df_join.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3a2061-a0e7-466e-9552-b520c484082f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonGroupingAgg(keys=[state#15859], functions=[finalmerge_count(merge count#17764L) AS count(1)#17758L, finalmerge_sum(merge sum#17766) AS sum(deaths)#17761, finalmerge_sum(merge sum#17768L) AS sum(deaths)#17760L])\n         +- PhotonShuffleExchangeSource\n            +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#20644]\n               +- PhotonShuffleExchangeSink hashpartitioning(state#15859, 10)\n                  +- PhotonGroupingAgg(keys=[state#15859], functions=[partial_count(1) AS count#17764L, partial_sum(cast(deaths#15902 as double)) AS sum#17766, partial_sum(deaths#15902) AS sum#17768L])\n                     +- PhotonProject [state#15859, coalesce(try_cast(deaths#15862 as int), 0) AS deaths#15902]\n                        +- PhotonRowToColumnar\n                           +- FileScan csv [state#15859,deaths#15862] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/COVID/covid-19-data], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<state:string,deaths:string>\n\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n"
     ]
    }
   ],
   "source": [
    "df_groupby.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc607897-a3d1-42fb-94ac-b6f3e61fcac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Transformers (Lazy) vs Actions (Eager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "babb84c5-ce5f-4dfe-bc61-f4d8777a7177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ec1a24-8fd8-4c06-8e78-2496d1d1bb46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n→ Transformation 1: Filtering for California state\n  ✓ Transformation registered (NOT executed yet)\n\n→ Transformation 2: Filtering cases > 10\n  ✓ Transformation registered (NOT executed yet)\n\n→ Transformation 3: Selecting date, county, cases, deaths\n  ✓ Transformation registered (NOT executed yet)\n\n→ Transformation 4: Adding severity_level column\n  ✓ Transformation registered (NOT executed yet)\n\n--------------------------------------------------------------------------------\nIMPORTANT: All transformations above are LAZY!\nNo actual data processing has occurred yet.\nSpark just built an execution plan (DAG - Directed Acyclic Graph)\n--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Transformation 1: Filter for California\n",
    "print(\"\\n→ Transformation 1: Filtering for California state\")\n",
    "california_df = df.filter(col(\"state\") == \"California\")\n",
    "print(\"  ✓ Transformation registered (NOT executed yet)\")\n",
    "\n",
    "# Transformation 2: Filter for cases > 10\n",
    "print(\"\\n→ Transformation 2: Filtering cases > 10\")\n",
    "high_cases_df = california_df.filter(col(\"cases\") > 10)\n",
    "print(\"  ✓ Transformation registered (NOT executed yet)\")\n",
    "\n",
    "# Transformation 3: Select specific columns\n",
    "print(\"\\n→ Transformation 3: Selecting date, county, cases, deaths\")\n",
    "selected_df = high_cases_df.select(\"date\", \"county\", \"cases\", \"deaths\")\n",
    "print(\"  ✓ Transformation registered (NOT executed yet)\")\n",
    "\n",
    "# Transformation 4: Add a new column\n",
    "print(\"\\n→ Transformation 4: Adding severity_level column\")\n",
    "transformed_df = selected_df.withColumn(\n",
    "    \"severity_level\",\n",
    "    when(col(\"cases\") < 50, \"Low\")\n",
    "    .when(col(\"cases\") < 200, \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "print(\"  ✓ Transformation registered (NOT executed yet)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"IMPORTANT: All transformations above are LAZY!\")\n",
    "print(\"No actual data processing has occurred yet.\")\n",
    "print(\"Spark just built an execution plan (DAG - Directed Acyclic Graph)\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52d403dc-3bcf-4e0e-931a-8a53259d2c6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e34a35-b795-4d37-9adb-dec812469b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n→ Action 1: show() - Display the results\n  (This triggers execution of ALL transformations above)\n+----------+-----------+-----+------+--------------+\n|      date|     county|cases|deaths|severity_level|\n+----------+-----------+-----+------+--------------+\n|2020-02-26|     Solano|   11|     0|           Low|\n|2020-02-27|     Solano|   11|     0|           Low|\n|2020-02-28|     Solano|   11|     0|           Low|\n|2020-02-29|     Solano|   11|     0|           Low|\n|2020-03-01|     Solano|   12|     0|           Low|\n|2020-03-02|     Solano|   12|     0|           Low|\n|2020-03-03|Santa Clara|   11|     0|           Low|\n|2020-03-03|     Solano|   12|     0|           Low|\n|2020-03-04|Santa Clara|   14|     0|           Low|\n|2020-03-04|     Solano|   12|     0|           Low|\n+----------+-----------+-----+------+--------------+\nonly showing top 10 rows\n\n→ Action 2: count() - Count the number of rows\n  (This triggers execution again)\n  Result: 20,606 rows found\n\n→ Action 3: collect() - Collect first 3 rows to driver\n  (This triggers execution and brings data to driver memory)\n  Result: Collected 3 rows to driver\n  Row 1: Date=2020-02-26, County=Solano, Cases=11\n  Row 2: Date=2020-02-27, County=Solano, Cases=11\n  Row 3: Date=2020-02-28, County=Solano, Cases=11\n\n→ Action 4: Aggregation - Calculate total cases\n  (This triggers execution)\n  Result: Total cases = 505,061,725.0\n"
     ]
    }
   ],
   "source": [
    "# Action 1: show()\n",
    "print(\"\\n→ Action 1: show() - Display the results\")\n",
    "print(\"  (This triggers execution of ALL transformations above)\")\n",
    "transformed_df.show(10)\n",
    "\n",
    "# Action 2: count()\n",
    "print(\"\\n→ Action 2: count() - Count the number of rows\")\n",
    "print(\"  (This triggers execution again)\")\n",
    "row_count = transformed_df.count()\n",
    "print(f\"  Result: {row_count:,} rows found\")\n",
    "\n",
    "# Action 3: collect()\n",
    "print(\"\\n→ Action 3: collect() - Collect first 3 rows to driver\")\n",
    "print(\"  (This triggers execution and brings data to driver memory)\")\n",
    "collected_data = transformed_df.take(3)\n",
    "print(f\"  Result: Collected {len(collected_data)} rows to driver\")\n",
    "for i, row in enumerate(collected_data, 1):\n",
    "    print(f\"  Row {i}: Date={row['date']}, County={row['county']}, Cases={row['cases']}\")\n",
    "\n",
    "# Action 4: Aggregation\n",
    "print(\"\\n→ Action 4: Aggregation - Calculate total cases\")\n",
    "print(\"  (This triggers execution)\")\n",
    "total_cases = transformed_df.agg({\"cases\": \"sum\"}).collect()[0][0]\n",
    "print(f\"  Result: Total cases = {total_cases:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05f8f894-bce6-426f-86d0-cd668f2d75ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Query Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba26f78c-cd85-4336-a5e5-310387e02bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6-1. Filter Early Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40a22b7-7cb0-4772-9563-d56521453dd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.6931s, Results: 108 states\n\n✅ GOOD Practice: Filtering early\nCode: df.filter().groupBy().agg()\nTime: 0.8318s, Results: 108 states\n\n⚡ Performance improvement: -20.0% faster\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bad_practice = data \\\n",
    "    .groupBy(\"state\") \\\n",
    "    .agg(sum(\"cases\").alias(\"total_cases\")) \\\n",
    "    .filter(col(\"total_cases\") > 10000)\n",
    "bad_count = bad_practice.count()\n",
    "bad_time = time.time() - start_time\n",
    "print(\"Time: {:.4f}s, Results: {} states\".format(bad_time, bad_count))\n",
    "\n",
    "print(\"\\n✅ GOOD Practice: Filtering early\")\n",
    "print(\"Code: df.filter().groupBy().agg()\")\n",
    "start_time = time.time()\n",
    "good_practice = data \\\n",
    "    .filter(col(\"cases\") > 0) \\\n",
    "    .groupBy(\"state\") \\\n",
    "    .agg(sum(\"cases\").alias(\"total_cases\")) \\\n",
    "    .filter(col(\"total_cases\") > 10000)\n",
    "good_count = good_practice.count()\n",
    "good_time = time.time() - start_time\n",
    "print(\"Time: {:.4f}s, Results: {} states\".format(good_time, good_count))\n",
    "\n",
    "improvement = ((bad_time - good_time) / bad_time * 100)\n",
    "print(\"\\n⚡ Performance improvement: {:.1f}% faster\".format(improvement))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77b764c7-659e-4f29-aba5-d9e3dc9fcf73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6-2. Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa9e1da-7bbb-4f2d-8af4-9712c9b8dacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shuffle partitions: 10\n\n→ Repartitioning by 'state' (DataFrame API)\n+-----------+\n|total_cases|\n+-----------+\n|505068688  |\n+-----------+\n\nQuery time (warm cache, no table persist): 0.6301s\n"
     ]
    }
   ],
   "source": [
    "print(\"Current shuffle partitions:\", spark.conf.get(\"spark.sql.shuffle.partitions\"))\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"10\")\n",
    "\n",
    "print(\"\\n→ Repartitioning by 'state' (DataFrame API)\")\n",
    "data_partitioned = data.repartition(10, F.col(\"state\"))\n",
    "\n",
    "_ = (data_partitioned\n",
    "     .where(F.col(\"state\") == \"California\")\n",
    "     .agg(F.sum(\"cases\").alias(\"total_cases\"))\n",
    "     .collect())\n",
    "\n",
    "start = time.time()\n",
    "partitioned_result = (data_partitioned\n",
    "    .where(F.col(\"state\") == \"California\")\n",
    "    .agg(F.sum(\"cases\").alias(\"total_cases\")))\n",
    "partitioned_result.show(truncate=False)\n",
    "print(\"Query time (warm cache, no table persist): {:.4f}s\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc551025-80ea-4c62-a782-fe34bf69e59e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6-3. Repartitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a87bb6-135a-4c1c-8879-93c126407acd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[Baseline] No Repartitioning\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_cases</th></tr></thead><tbody><tr><td>505068688</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         505068688
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_cases",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Query time: 1.0362s\n\n[Optimized] Repartitioning by 'state' (10 partitions)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_cases</th></tr></thead><tbody><tr><td>505068688</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         505068688
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_cases",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned Query time: 0.6944s\n\n⚡ Performance improvement: 33.0% faster\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n[Baseline] No Repartitioning\")\n",
    "start_time_base = time.time()\n",
    "base_result = data.filter(\n",
    "    col(\"state\") == \"California\"\n",
    ").agg(\n",
    "    sum(\"cases\").alias(\"total_cases\")\n",
    ")\n",
    "display(base_result)\n",
    "base_time = time.time() - start_time_base\n",
    "print(\"Base Query time: {:.4f}s\".format(base_time))\n",
    "\n",
    "print(\"\\n[Optimized] Repartitioning by 'state' (10 partitions)\")\n",
    "df_partitioned = data.repartition(10, \"state\")\n",
    "\n",
    "start_time_part = time.time()\n",
    "partitioned_result = df_partitioned.filter(\n",
    "    col(\"state\") == \"California\"\n",
    ").agg(\n",
    "    sum(\"cases\").alias(\"total_cases\")\n",
    ")\n",
    "display(partitioned_result)\n",
    "part_time = time.time() - start_time_part\n",
    "print(\"Partitioned Query time: {:.4f}s\".format(part_time))\n",
    "\n",
    "# 성능 비교\n",
    "if base_time > part_time:\n",
    "    improvement = ((base_time - part_time) / base_time * 100)\n",
    "    print(\"\\n⚡ Performance improvement: {:.1f}% faster\".format(improvement))\n",
    "else:\n",
    "    print(\"\\n⚠️ Note: Partitioning didn't show improvement in this run (may be due to small dataset or warm cache).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77440f10-f8b1-431c-9a98-fd181b8140c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n→ Writing to standard Parquet...\n   ✓ Saved to: /Volumes/de/de/de/covid_pipeline_output/covid_data_parquet\n   ✓ Verified: 1227060 records written\n\n→ Writing to partitioned Parquet (by year)...\n   ✓ Saved to: /Volumes/de/de/de/covid_pipeline_output/covid_data_by_year\n   ✓ Verified: 1227060 records written\n\n→ Writing to Delta format...\n   ✓ Saved to: /Volumes/de/de/de/covid_pipeline_output/state_summary_delta\n   ✓ Verified: 478 records written\n\n================================================================================\n✅ ALL FILES WRITTEN SUCCESSFULLY!\n================================================================================\n\nSaved files:\n1. Standard Parquet: /Volumes/de/de/de/covid_pipeline_output/covid_data_parquet\n2. Partitioned Parquet: /Volumes/de/de/de/covid_pipeline_output/covid_data_by_year\n3. Delta format: /Volumes/de/de/de/covid_pipeline_output/state_summary_delta\n"
     ]
    }
   ],
   "source": [
    "output_base = \"/Volumes/de/de/de/covid_pipeline_output\"\n",
    "\n",
    "# 1. Standard Parquet\n",
    "print(\"\\n→ Writing to standard Parquet...\")\n",
    "output_path_parquet = \"{}/covid_data_parquet\".format(output_base)\n",
    "data.write.mode(\"overwrite\").parquet(output_path_parquet)\n",
    "print(\"   ✓ Saved to: {}\".format(output_path_parquet))\n",
    "\n",
    "# Verify\n",
    "read_back = spark.read.parquet(output_path_parquet)\n",
    "print(\"   ✓ Verified: {} records written\".format(read_back.count()))\n",
    "\n",
    "# 2. Partitioned Parquet (by year)\n",
    "print(\"\\n→ Writing to partitioned Parquet (by year)...\")\n",
    "output_path_partitioned = \"{}/covid_data_by_year\".format(output_base)\n",
    "data.withColumn(\"year\", year(col(\"date\"))) \\\n",
    "    .write.mode(\"overwrite\").partitionBy(\"year\").parquet(output_path_partitioned)\n",
    "print(\"   ✓ Saved to: {}\".format(output_path_partitioned))\n",
    "\n",
    "# Verify\n",
    "read_back2 = spark.read.parquet(output_path_partitioned)\n",
    "print(\"   ✓ Verified: {} records written\".format(read_back2.count()))\n",
    "\n",
    "# 3. Delta format\n",
    "print(\"\\n→ Writing to Delta format...\")\n",
    "output_path_delta = \"{}/state_summary_delta\".format(output_base)\n",
    "data.groupBy(\"state\") \\\n",
    "    .agg(sum(\"cases\").alias(\"total_cases\"), sum(\"deaths\").alias(\"total_deaths\")) \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\").save(output_path_delta)\n",
    "print(\"   ✓ Saved to: {}\".format(output_path_delta))\n",
    "\n",
    "# Verify\n",
    "read_back3 = spark.read.format(\"delta\").load(output_path_delta)\n",
    "print(\"   ✓ Verified: {} records written\".format(read_back3.count()))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ ALL FILES WRITTEN SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"1. Standard Parquet: {}\".format(output_path_parquet))\n",
    "print(\"2. Partitioned Parquet: {}\".format(output_path_partitioned))\n",
    "print(\"3. Delta format: {}\".format(output_path_delta))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark_demo_assignment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}